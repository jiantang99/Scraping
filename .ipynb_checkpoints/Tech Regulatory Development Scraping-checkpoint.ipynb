{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d464d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request,sys,time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11561f91",
   "metadata": {},
   "source": [
    "### Scraper for The Treasury Cloud Advisory\n",
    "\n",
    "##### Uses URL of searched query, loops through each page, takes the title and link, and scans link to get the date of publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99b0d1",
   "metadata": {},
   "source": [
    "### Check if document can get date. If cannot, then just skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "522e266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results:  146\n",
      "Total number of pages:  8\n",
      "https://home.treasury.gov/news/press-releases/jy1252\n",
      "February 8, 2023\n",
      "https://home.treasury.gov/news/press-releases/jl0248\n",
      "November 4, 2015\n",
      "https://home.treasury.gov/services/government-shared-services/enterprise-business-solutions/enterprise-content-management-ecm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m     dates_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFind yourself\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate-format field field--name-field-news-publication-date field--type-datetime field--label-hidden field__item\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     dates_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFind yourself\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# Getting total results\n",
    "url = 'https://search.treasury.gov/search?affiliate=treas&page=1&query=cloud+advisory'\n",
    "try:\n",
    "     # this might throw an exception if something goes wrong.\n",
    "     page = requests.get(url) \n",
    " # this describes what to do if an exception is thrown \n",
    "except Exception as e:    \n",
    "\n",
    "    # get the exception information\n",
    "    error_type, error_obj, error_info = sys.exc_info()      \n",
    "\n",
    "    #print the link that cause the problem\n",
    "    print ('ERROR FOR LINK:',url)\n",
    "\n",
    "    #print error info and line that threw the exception                          \n",
    "    print (error_type, 'Line:', error_info.tb_lineno)\n",
    "        \n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "titles = soup.find_all('h4',attrs={'class':'title'})\n",
    "results_count = soup.find_all('li',attrs={'id':'results-count'})\n",
    "for a in results_count:\n",
    "    results_count = int(a.text.strip().split(' ')[0])\n",
    "print(\"Total results: \", results_count)\n",
    "\n",
    "if results_count % len(titles) != 0:\n",
    "    total_pages = math.ceil(results_count / len(titles))\n",
    "else:\n",
    "    total_pages = math.floor(results_count / len(titles))\n",
    "    \n",
    "print(\"Total number of pages: \", total_pages)\n",
    "\n",
    "titles_list = list()\n",
    "links_list = list()\n",
    "dates_list = list()\n",
    "\n",
    "\n",
    "for page in range(1, total_pages+1):\n",
    "    \n",
    "    # Base URL\n",
    "    url = 'https://search.treasury.gov/search?affiliate=treas&page={pagenum}&query=cloud+advisory'.format(pagenum=page)\n",
    "    try:\n",
    "         # this might throw an exception if something goes wrong.\n",
    "         page = requests.get(url) \n",
    "     # this describes what to do if an exception is thrown \n",
    "    except Exception as e:    \n",
    "\n",
    "        # get the exception information\n",
    "        error_type, error_obj, error_info = sys.exc_info()      \n",
    "\n",
    "        #print the link that cause the problem\n",
    "        print ('ERROR FOR LINK:',url)\n",
    "\n",
    "        #print error info and line that threw the exception                          \n",
    "        print (error_type, 'Line:', error_info.tb_lineno)\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    # Getting all links and titles\n",
    "    titles = soup.find_all('h4',attrs={'class':'title'})\n",
    "    links=soup.find_all('span',attrs={'class':'url'})\n",
    "\n",
    "    # Adding titles and links to list\n",
    "    for a in titles:\n",
    "        titles_list.append([b.strip() for b in a.text.strip().split('\\n') if b.strip()])\n",
    "\n",
    "    for a in links:\n",
    "        links_list.append([b.strip() for b in a.text.strip().split('\\n') if b.strip()])\n",
    "\n",
    "\n",
    "# Create list for dates and add to dataframe\n",
    "for link in links_list:\n",
    "    url = link[0]\n",
    "    print(url)\n",
    "    if url.__contains__('pdf'):\n",
    "        dates_list.append('Find yourself')\n",
    "        continue\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        error_type, error_obj, error_info = sys.exc_info()\n",
    "        print ('ERROR FOR LINK:',url)                       \n",
    "        print (error_type, 'Line:', error_info.tb_lineno)\n",
    "        dates_list.append('Find yourself')\n",
    "        continue\n",
    "\n",
    "    date = soup.find('div', class_='date-format field field--name-field-news-publication-date field--type-datetime field--label-hidden field__item')\n",
    "    if date is None:\n",
    "        dates_list.append('Find yourself')\n",
    "        continue\n",
    "    else:\n",
    "        dates_list.append(date.text.strip())\n",
    "    print(date)\n",
    "    \n",
    "# Create dataframe for links and titles\n",
    "d = {'Title': titles_list, 'Link': links_list, 'Date':dates_list}\n",
    "print(len(titles_list))\n",
    "print(len(links_list))\n",
    "print(len(dates_list))\n",
    "\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "# Importing to csv\n",
    "#df.to_csv(r'C:\\Users\\65936\\\\OneDrive\\Desktop\\MAS\\\\USDeptOfTheTreasury.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4ffff",
   "metadata": {},
   "source": [
    "#### Testing find next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97b08ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 8, 2023\n"
     ]
    }
   ],
   "source": [
    "url = 'https://search.treasury.gov/search?affiliate=treas&page=1&query=cloud+advisory'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "title = soup.find('h4',attrs={'class':'title'})\n",
    "link =soup.find('span',attrs={'class':'url'})\n",
    "date = BeautifulSoup(requests.get(link.text.strip()).text, \"html.parser\").find('div', class_='date-format field field--name-field-news-publication-date field--type-datetime field--label-hidden field__item').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "277ab19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PageElement.find_next of <h4 class=\"title\">\n",
      "<a data-click='{\"position\":1,\"module_code\":\"I14Y\"}' href=\"https://home.treasury.gov/news/press-releases/jy1252\">New Treasury Report Assesses Opportunities, Challenges Facing Financial Sector <strong>Cloud</strong>-Based Technology Adoption | U.S. Department of the Treasury</a>\n",
      "</h4>>\n",
      "<bound method PageElement.find_next of <h4 class=\"title\">\n",
      "<a data-click='{\"position\":1,\"module_code\":\"I14Y\"}' href=\"https://home.treasury.gov/news/press-releases/jy1252\">New Treasury Report Assesses Opportunities, Challenges Facing Financial Sector <strong>Cloud</strong>-Based Technology Adoption | U.S. Department of the Treasury</a>\n",
      "</h4>>\n",
      "<bound method PageElement.find_next of <h4 class=\"title\">\n",
      "<a data-click='{\"position\":1,\"module_code\":\"I14Y\"}' href=\"https://home.treasury.gov/news/press-releases/jy1252\">New Treasury Report Assesses Opportunities, Challenges Facing Financial Sector <strong>Cloud</strong>-Based Technology Adoption | U.S. Department of the Treasury</a>\n",
      "</h4>>\n",
      "<bound method PageElement.find_next of <h4 class=\"title\">\n",
      "<a data-click='{\"position\":1,\"module_code\":\"I14Y\"}' href=\"https://home.treasury.gov/news/press-releases/jy1252\">New Treasury Report Assesses Opportunities, Challenges Facing Financial Sector <strong>Cloud</strong>-Based Technology Adoption | U.S. Department of the Treasury</a>\n",
      "</h4>>\n",
      "<bound method PageElement.find_next of <h4 class=\"title\">\n",
      "<a data-click='{\"position\":1,\"module_code\":\"I14Y\"}' href=\"https://home.treasury.gov/news/press-releases/jy1252\">New Treasury Report Assesses Opportunities, Challenges Facing Financial Sector <strong>Cloud</strong>-Based Technology Adoption | U.S. Department of the Treasury</a>\n",
      "</h4>>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = soup.find('h4',attrs={'class':'title'})\n",
    "for i in range(0,5):\n",
    "    print(title.find_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee2cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
