{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbaaf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request,sys,time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda03087",
   "metadata": {},
   "source": [
    "#### Go to page, reject cookies, enter search, click on 'Past year', get total results, loop through total pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d67c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.ecb.europa.eu/pub/pubbydate/html/index.en.html')\n",
    "\n",
    "# Reject cookies\n",
    "button = driver.find_element(By.XPATH,\"//*[text()='I do not accept the use of cookies']\")\n",
    "button.click()\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Get HTML code\n",
    "html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "div_element = soup.find('div', class_='lazy-load loaded')\n",
    "allDates = div_element.find_all('div',class_='date') # All dates\n",
    "allTitleBlocks = div_element.find_all('dd') # All title blocks\n",
    "\n",
    "titles = list()\n",
    "links = list()\n",
    "dates = list()\n",
    "\n",
    "monthDict = {\t1:'Janauary',\n",
    "\t\t2:'February',\n",
    "\t\t3:'March',\n",
    "\t\t4:'April',\n",
    "\t\t5:'May',\n",
    "\t\t6:'June',\n",
    "\t\t7:'July',\n",
    "\t\t8:'August',\n",
    "\t\t9:'September',\n",
    "\t\t10:'October',\n",
    "\t\t11:'November',\n",
    "\t\t12:'December'\t\t}\n",
    "\n",
    "month = monthDict[datetime.now().month]\n",
    "year = str(datetime.now().year)\n",
    "\n",
    "for a in allDates:\n",
    "    if a.text.find(year) != -1 and a.text.find(month) != -1:\n",
    "        dates.append(a.text)                                  # All dates\n",
    "\n",
    "preLink = 'https://www.ecb.europa.eu'\n",
    "        \n",
    "for a in allTitleBlocks:\n",
    "    titleBlock = a.find('div',class_='title')\n",
    "    if titleBlock is not None:\n",
    "        titles.append(titleBlock.find('a', href=True).text)   # All titles\n",
    "        newLink = preLink + titleBlock.find('a', href=True)['href'] \n",
    "        links.append(newLink)                                 # All links\n",
    "        \n",
    "links = links[0:len(dates)]                                   # Slice list to get same length as dates\n",
    "titles = titles[0:len(dates)]                                 # Indexes of dates, links, and titles match, so simple slicing will work\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# d = {'Title': titles, 'Link': links, 'Date': dates}\n",
    "# df = pd.DataFrame(data=d)\n",
    "# df.to_csv(r'C:\\Users\\65936\\\\OneDrive\\Desktop\\MAS\\\\ECB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7cff978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 July 2023', '4 July 2023', '4 July 2023', '4 July 2023', '3 July 2023']\n"
     ]
    }
   ],
   "source": [
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c1869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
